{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PRÉ-PROCESSAMENTO DE TEXTO"
      ],
      "metadata": {
        "id": "j4h50WLCYW_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBJETIVOS DESSE NOTEBOOK/AULA:** Ensinar os principais passos de pré-processamento textual com código e aplicar esse conhecimento num pequeno dataset."
      ],
      "metadata": {
        "id": "LX_DyqlOYdeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAREFAS:\n",
        "\n",
        "- Como limpar textos;\n",
        "- Como tokenizar frases;\n",
        "- Como remover stopwords;\n",
        "- Como aplicar stemming e lematização.\n",
        "\n",
        "Vamos usar as bibliotecas: `re`, `nltk` e `spaCy`."
      ],
      "metadata": {
        "id": "jEuEy1DgYrgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LIMPEZA BÁSICA (Remoção de pontuação, números...)**"
      ],
      "metadata": {
        "id": "80P40cZGY4fN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de analisar ou usar um texto em modelos de NLP, é fundamental limpar o texto cru para facilitar o processamento e melhorar os resultados.\n",
        "\n",
        "Por que isso é importante?\n",
        "\n",
        "**Reduzir o ruído**\n",
        "\n",
        "Pontuação, números, símbolos e caracteres especiais muitas vezes não carregam significado útil para tarefas de linguagem (como classificação de sentimento, por exemplo). Se esses elementos ficarem no texto, eles podem atrapalhar o modelo, que vai “ver” muitas coisas irrelevantes.\n",
        "\n",
        "**Uniformizar os dados**\n",
        "\n",
        "A limpeza ajuda a deixar o texto mais homogêneo. Por exemplo, sem pontuação e em letras minúsculas, palavras iguais aparecem sempre da mesma forma (“Casa”, “casa,” “casa.” → “casa”). Isso evita que o modelo trate variações iguais como coisas diferentes.\n",
        "\n",
        "**Diminuir o vocabulário**\n",
        "\n",
        "Remover caracteres desnecessários reduz o número de tokens únicos, deixando o vocabulário mais “limpo” e gerenciável. Isso é importante para modelos tradicionais, pois melhora a eficiência e evita “overfitting” em dados ruidosos.\n",
        "\n",
        "**Facilitar tarefas subsequentes**\n",
        "\n",
        "Passos como tokenização, remoção de stopwords, lematização e stemming funcionam melhor quando o texto está limpo. Por exemplo, se houver vírgulas ou pontos grudados às palavras, a tokenização pode separar de forma incorreta.\n",
        "\n",
        "**Melhorar a qualidade dos dados para modelos**\n",
        "\n",
        "Modelos de machine learning e deep learning aprendem padrões a partir dos dados de entrada. Quanto mais limpos e consistentes forem esses dados, mais precisos e robustos serão os modelos gerados."
      ],
      "metadata": {
        "id": "6ZKiSbj9fzDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "texto = \"Oi! Esse é um exemplo de texto com pontuação, números como 123 e símbolos #NLP :)\"\n",
        "\n",
        "# Remover pontuação, números e símbolos, às vezes, é essencial para deixar o dataset limpo e os textos mais claros antes de colocar para um modelo aprender\n",
        "texto_limpo = re.sub(r\"[^\\w\\s]\", \"\", texto)  # remove pontuação\n",
        "texto_limpo = re.sub(r\"\\d+\", \"\", texto_limpo)  # remove números\n",
        "\n",
        "print(\"Texto limpo:\", texto_limpo)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "V1CKcUXBZBVc",
        "outputId": "a2697c07-4d56-403b-f20c-57ddbcb1b007",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto limpo: Oi Esse é um exemplo de texto com pontuação números como  e símbolos NLP \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mini tarefa 1:\n",
        "Crie uma função `limpar_texto` que remova pontuação, números e transforme o texto para minúsculas.\n"
      ],
      "metadata": {
        "id": "NzDdUvMIZSIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto1 = \"Oi! Esse é um exemplo de texto com pontuação, números como 123 e símbolos #NLP :)\"\n",
        "\n",
        "def limpar_texto(texto_sujo):\n",
        "  texto_limpo = re.sub(r\"[^\\w\\s]\", \"\", texto_sujo) # sem pontuação\n",
        "  texto_limpo = re.sub(r\"\\d+\", \"\", texto_limpo)    # sem números\n",
        "  texto_limpo = texto_limpo.lower()                # transforma em minúsculo\n",
        "  print(\"Texto limpo:\", texto_limpo)\n",
        "\n",
        "limpar_texto(texto1)"
      ],
      "metadata": {
        "id": "zAaaHCqBZaBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976ff6e0-b89f-4edf-867c-e989abe00713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto limpo: oi esse é um exemplo de texto com pontuação números como  e símbolos nlp \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOKENIZAÇÃO (Um token pode ser uma palavra, uma expressão...)"
      ],
      "metadata": {
        "id": "zQ2-GTk_ZoZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenização é o processo de dividir um texto em unidades menores chamadas tokens.\n",
        "Normalmente, esses tokens são palavras, mas podem ser também frases, caracteres ou subpalavras, dependendo do tipo de tokenização usada.\n",
        "\n",
        "Por exemplo, a frase:\n",
        "\n",
        "\"Hoje o dia está lindo.\"\n",
        "\n",
        "Pode ser tokenizada em palavras:\n",
        "[\"Hoje\", \"o\", \"dia\", \"está\", \"lindo\", \".\"]\n",
        "\n",
        "\n",
        "POR QUE É IMPORTANTE TOKENIZAR?\n",
        "\n",
        "**Transformar texto bruto em dados estruturados**\n",
        "\n",
        "Modelos de NLP não entendem diretamente uma sequência de caracteres. Eles trabalham com unidades menores, os tokens. Tokenizar o texto é transformar uma sequência contínua de texto em uma lista organizada de pedaços que o computador consegue manipular.\n",
        "\n",
        "**Base para etapas posteriores**\n",
        "\n",
        "Muitas etapas essenciais de NLP, como remoção de stopwords, lematização, stemming, análise sintática e vetorização, dependem de tokens. Sem tokenização, essas operações não podem ser aplicadas corretamente.\n",
        "\n",
        "**Permite análise granular**\n",
        "\n",
        "Tokenização permite analisar texto palavra a palavra, facilitando a extração de informações, como frequência, padrões, sentimentos, entidades nomeadas, etc.\n",
        "\n",
        "**Flexibilidade para diferentes tarefas**\n",
        "\n",
        "Dependendo da tarefa, podemos usar diferentes tipos de tokenização: por palavras, por sentenças, por caracteres ou subpalavras (como em modelos Transformers). Isso possibilita adaptar o processamento à complexidade do problema."
      ],
      "metadata": {
        "id": "yaRm9P_igUDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# garanta o download (roda só uma vez)\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "texto = \"Esse é um texto simples para tokenização.\"\n",
        "tokens = word_tokenize(texto, language=\"portuguese\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "YI08Vg-cZwqN",
        "outputId": "a8feb47b-1cbe-4b0c-b5b6-94de5d084c5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Esse', 'é', 'um', 'texto', 'simples', 'para', 'tokenização', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mini tarefa 2:\n",
        "Aplique a tokenização em três frases diferentes à sua escolha.\n"
      ],
      "metadata": {
        "id": "Ckhzvtcca_0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Corinthians é o maior.\"\n",
        "tokens = word_tokenize(texto, language=\"portuguese\")\n",
        "print(tokens)\n",
        "\n",
        "texto = \"He who controls the spice controls the universe.\"\n",
        "tokens = word_tokenize(texto, language=\"english\")\n",
        "print(tokens)\n",
        "\n",
        "texto = \"Que a Força esteja com você.\"\n",
        "tokens = word_tokenize(texto, language=\"portuguese\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "4izhzLr5bEQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa4c9a4-17e1-465f-ec5a-092cc7bbf106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Corinthians', 'é', 'o', 'maior', '.']\n",
            "['He', 'who', 'controls', 'the', 'spice', 'controls', 'the', 'universe', '.']\n",
            "['Que', 'a', 'Força', 'esteja', 'com', 'você', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REMOÇÃO DE STOPWORDS"
      ],
      "metadata": {
        "id": "k-yP5_PTbL7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopwords são palavras muito comuns em uma língua que geralmente têm pouco significado próprio no contexto de análise textual.\n",
        "Exemplos em português: “de”, “a”, “o”, “que”, “e”, “para”.\n",
        "\n",
        "PARA QUE SERVE?\n",
        "\n",
        "**Reduzir o ruído**\n",
        "\n",
        "Stopwords aparecem com muita frequência e não agregam valor semântico significativo para a maioria das tarefas de NLP, como análise de sentimento, classificação de texto, etc.\n",
        "\n",
        "**Diminuir o tamanho do vocabulário**\n",
        "\n",
        "Remover essas palavras ajuda a reduzir o número de tokens únicos, simplificando os dados e acelerando o processamento.\n",
        "\n",
        "**Focar nas palavras relevantes**\n",
        "\n",
        "Ao eliminar stopwords, destacam-se termos mais importantes que carregam o significado real do texto, facilitando a identificação de padrões.\n",
        "\n",
        "**Melhorar o desempenho dos modelos**\n",
        "\n",
        "Com menos tokens irrelevantes, os modelos tendem a aprender melhor as características importantes, aumentando a eficiência e a precisão."
      ],
      "metadata": {
        "id": "qbo5hfemgwbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words(\"portuguese\"))\n",
        "tokens_sem_stopwords = [token for token in tokens if token not in stop_words]\n",
        "print(tokens_sem_stopwords)\n"
      ],
      "metadata": {
        "id": "9SCbWOyBbIuV",
        "outputId": "249ec3b8-c130-4f51-ac0f-11349a08b27c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Que', 'Força', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mini tarefa 3:\n",
        "Crie uma função `remover_stopwords` que receba uma lista de tokens e retorne apenas as palavras relevantes.\n"
      ],
      "metadata": {
        "id": "UKD3TmK3bQBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remover_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words(\"portuguese\"))\n",
        "    tokens_filtrados = [token for token in tokens if token.lower() not in stop_words]\n",
        "    return tokens_filtrados\n",
        "\n",
        "texto = \"Este é um exemplo simples para testar a remoção de stopwords em português.\"\n",
        "\n",
        "tokens = word_tokenize(texto, language=\"portuguese\")\n",
        "\n",
        "tokens_sem_stopwords = remover_stopwords(tokens)\n",
        "\n",
        "print(tokens_sem_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFlyPJmdDWUK",
        "outputId": "d69e9dc3-eec0-4703-913f-2d7303877682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['exemplo', 'simples', 'testar', 'remoção', 'stopwords', 'português', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEMMING E LEMATIZAÇÃO"
      ],
      "metadata": {
        "id": "L_m52tD9bU2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ambos são técnicas de redução de palavras à sua forma base ou raiz, muito usadas no pré-processamento de texto para agrupar variações de uma palavra em uma única representação.\n",
        "\n",
        "**Stemming**\n",
        "\n",
        "É o processo que corta os sufixos das palavras para chegar a uma raiz comum, geralmente sem considerar o significado da palavra.\n",
        "\n",
        "Como funciona: regras simples, como remover terminações, às vezes de forma \"bruta\" e sem garantir uma palavra real no final.\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "palavras “amando”, “amaria”, “amar” → podem virar “am”\n",
        "\n",
        "“computador”, “computação” → “comput”\n",
        "\n",
        "Vantagem: rápido e fácil de aplicar.\n",
        "\n",
        "Desvantagem: pode gerar raízes artificiais, que não são palavras válidas (ex: “am”)."
      ],
      "metadata": {
        "id": "rWbkHACQhBcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lematização**\n",
        "\n",
        "É o processo que reduz a palavra à sua forma canônica ou dicionarizada, chamada lematização.\n",
        "\n",
        "Como funciona: usa análise morfológica e dicionários para encontrar a forma base correta.\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "“amando”, “amaria”, “amar” → todos lematizados para “amar”\n",
        "\n",
        "“melhores” → lematizado para “melhor”\n",
        "\n",
        "Vantagem: resultados mais precisos e compreensíveis.\n",
        "\n",
        "Desvantagem: mais lento e complexo, requer recursos linguísticos."
      ],
      "metadata": {
        "id": "M6G1BxmUhQ1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm\n"
      ],
      "metadata": {
        "id": "5Hv6OanNbzZa",
        "outputId": "18c6b43f-95f5-45d8-f221-4d55af2802c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RSLPStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('rslp')\n",
        "\n",
        "\n",
        "stemmer = RSLPStemmer()\n",
        "tokens_stemm = [stemmer.stem(token) for token in tokens_sem_stopwords]\n",
        "print(\"Stemming:\", tokens_stemm)\n",
        "\n",
        "# Para lematização em português, usaremos spaCy\n",
        "import spacy\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "doc = nlp(\" \".join(tokens_sem_stopwords))\n",
        "tokens_lema = [token.lemma_ for token in doc]\n",
        "print(\"Lematização:\", tokens_lema)\n"
      ],
      "metadata": {
        "id": "UewlhHpLbZWl",
        "outputId": "ffeb0671-8df9-41af-ae56-e49216abb599",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming: ['diss', '.']\n",
            "Lematização: ['dizer', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mini tarefa 4:\n",
        "Compare os resultados de stemming e lematização. Qual parece mais legível? Traga novas frases e exemplos para poder embasar a comparação.\n"
      ],
      "metadata": {
        "id": "j4GyvwNwcGEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Foi o que ela disse.\"\n",
        "\n",
        "tokens = word_tokenize(texto, language=\"portuguese\")\n",
        "\n",
        "# Stemming\n",
        "stemmer = RSLPStemmer()\n",
        "tokens_stemm = [stemmer.stem(token) for token in tokens]\n",
        "print(\"Stemming:\", tokens_stemm)\n",
        "\n",
        "# Lematização\n",
        "doc = nlp(\" \".join(tokens))\n",
        "tokens_lema = [token.lemma_ for token in doc]\n",
        "print(\"Lematização:\", tokens_lema)"
      ],
      "metadata": {
        "id": "a1Kkb0TgcFxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516d193e-98d1-41d6-cb3f-6f29dc62495e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming: ['foi', 'o', 'que', 'ela', 'diss', '.']\n",
            "Lematização: ['foi', 'o', 'que', 'ela', 'dizer', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dá pra ver que o stemming corta as palavras, deixando elas meio estranhas, como \"exempl\", \"remoç\" e \"portugu\".\n",
        "Já a lematização mantém as palavras certinhas, como \"exemplo\" e \"remoção\", o que faz muito mais sentido.\n",
        "Por isso, a lematização acaba sendo melhor pra entender o texto, e é mais útil para análise do conteúdo de forma mais clara."
      ],
      "metadata": {
        "id": "hofYG5P8o0k8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tarefa Final: Aplicando tudo em um dataset simples"
      ],
      "metadata": {
        "id": "aDhjXxTlcVg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Dataset manual com frases e emoções\n",
        "data = {\n",
        "    \"text\": [\n",
        "        \"Hoje o dia está lindo e me sinto muito bem.\",\n",
        "        \"Essa comida está horrível, não gostei.\",\n",
        "        \"Estou muito feliz com o meu resultado!\",\n",
        "        \"Não suporto mais esse trânsit@o terrível.\",\n",
        "        \"Que filme% maravilhoso, adorei cada segundo.\",\n",
        "        \"Foi um desastre total, tudo deu errado.\",\n",
        "        \"Estou animado para o final# de semana!\",\n",
        "        \"O atendimento foi péssimo, estou revoltado.\",\n",
        "        \"Ganhei um presente incr*ível hoje!\",\n",
        "        \"Me senti mal com aquele comentário.\"\n",
        "    ]\n",
        "\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.head()\n",
        "\n",
        "# --- Funções reutilizáveis ---\n",
        "\n",
        "def tokenizar(texto):\n",
        "    return word_tokenize(texto, language=\"portuguese\")\n",
        "\n",
        "def aplicar_stemming(tokens):\n",
        "    stemmer = RSLPStemmer()\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "def aplicar_lemmatizacao(tokens):\n",
        "    doc = nlp(\" \".join(tokens))\n",
        "    return [token.lemma_ for token in doc]\n",
        "\n",
        "# --- Aplicação no DataFrame ---\n",
        "\n",
        "# Pré-processamento: limpeza\n",
        "df[\"texto_limpo\"] = df[\"text\"].apply(limpar_texto)\n",
        "\n",
        "# Tokenização\n",
        "df[\"tokens\"] = df[\"texto_limpo\"].apply(tokenizar)\n",
        "\n",
        "# Remoção de stopwords (usando NLTK)\n",
        "df[\"sem_stopwords\"] = df[\"tokens\"].apply(remover_stopwords)\n",
        "\n",
        "# Nova coluna: texto pré-processado (sem stopwords, como string)\n",
        "df[\"texto_processado\"] = df[\"sem_stopwords\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# Stemming e lematização\n",
        "df[\"stemming\"] = df[\"sem_stopwords\"].apply(aplicar_stemming)\n",
        "df[\"lemmatizacao\"] = df[\"sem_stopwords\"].apply(aplicar_lemmatizacao)\n",
        "\n",
        "# Exibir resultado\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "display(df[[\"text\", \"texto_limpo\", \"tokens\", \"sem_stopwords\", \"stemming\", \"lemmatizacao\"]])"
      ],
      "metadata": {
        "id": "ulKri7becYzX",
        "outputId": "7d7977c7-c4b4-4104-8c40-6264890c9ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                           text  \\\n",
              "0   Hoje o dia está lindo e me sinto muito bem.   \n",
              "1        Essa comida está horrível, não gostei.   \n",
              "2        Estou muito feliz com o meu resultado!   \n",
              "3     Não suporto mais esse trânsit@o terrível.   \n",
              "4  Que filme% maravilhoso, adorei cada segundo.   \n",
              "5       Foi um desastre total, tudo deu errado.   \n",
              "6        Estou animado para o final# de semana!   \n",
              "7   O atendimento foi péssimo, estou revoltado.   \n",
              "8            Ganhei um presente incr*ível hoje!   \n",
              "9           Me senti mal com aquele comentário.   \n",
              "\n",
              "                                  texto_limpo  \\\n",
              "0  hoje o dia está lindo e me sinto muito bem   \n",
              "1        essa comida está horrível não gostei   \n",
              "2       estou muito feliz com o meu resultado   \n",
              "3     não suporto mais esse trânsito terrível   \n",
              "4   que filme maravilhoso adorei cada segundo   \n",
              "5       foi um desastre total tudo deu errado   \n",
              "6        estou animado para o final de semana   \n",
              "7   o atendimento foi péssimo estou revoltado   \n",
              "8            ganhei um presente incrível hoje   \n",
              "9          me senti mal com aquele comentário   \n",
              "\n",
              "                                                  tokens  \\\n",
              "0  [hoje, o, dia, está, lindo, e, me, sinto, muito, bem]   \n",
              "1            [essa, comida, está, horrível, não, gostei]   \n",
              "2          [estou, muito, feliz, com, o, meu, resultado]   \n",
              "3         [não, suporto, mais, esse, trânsito, terrível]   \n",
              "4       [que, filme, maravilhoso, adorei, cada, segundo]   \n",
              "5          [foi, um, desastre, total, tudo, deu, errado]   \n",
              "6           [estou, animado, para, o, final, de, semana]   \n",
              "7       [o, atendimento, foi, péssimo, estou, revoltado]   \n",
              "8                 [ganhei, um, presente, incrível, hoje]   \n",
              "9              [me, senti, mal, com, aquele, comentário]   \n",
              "\n",
              "                                 sem_stopwords  \\\n",
              "0               [hoje, dia, lindo, sinto, bem]   \n",
              "1                   [comida, horrível, gostei]   \n",
              "2                           [feliz, resultado]   \n",
              "3                [suporto, trânsito, terrível]   \n",
              "4  [filme, maravilhoso, adorei, cada, segundo]   \n",
              "5         [desastre, total, tudo, deu, errado]   \n",
              "6                     [animado, final, semana]   \n",
              "7            [atendimento, péssimo, revoltado]   \n",
              "8           [ganhei, presente, incrível, hoje]   \n",
              "9                     [senti, mal, comentário]   \n",
              "\n",
              "                              stemming  \\\n",
              "0          [hoj, dia, lind, sint, bem]   \n",
              "1                    [com, horr, gost]   \n",
              "2                      [feliz, result]   \n",
              "3              [suport, trânsit, terr]   \n",
              "4  [film, maravilh, ador, cad, segund]   \n",
              "5      [desastr, total, tud, deu, err]   \n",
              "6                 [anim, final, seman]   \n",
              "7                [atend, péss, revolt]   \n",
              "8              [ganh, pres, incr, hoj]   \n",
              "9                  [sent, mal, coment]   \n",
              "\n",
              "                                  lemmatizacao  \n",
              "0                 [hoje, dia, lir, sinto, bem]  \n",
              "1                   [comida, horrível, gostar]  \n",
              "2                           [feliz, resultado]  \n",
              "3                [suporto, trânsito, terrível]  \n",
              "4  [filme, maravilhoso, adorar, cada, segundo]  \n",
              "5          [desastre, total, tudo, dar, errar]  \n",
              "6                      [animar, final, semana]  \n",
              "7             [atendimento, péssimo, revoltar]  \n",
              "8           [ganhar, presente, incrível, hoje]  \n",
              "9                    [sentir, mal, comentário]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f023586-f677-4a27-9861-75f00f226c21\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>texto_limpo</th>\n",
              "      <th>tokens</th>\n",
              "      <th>sem_stopwords</th>\n",
              "      <th>stemming</th>\n",
              "      <th>lemmatizacao</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hoje o dia está lindo e me sinto muito bem.</td>\n",
              "      <td>hoje o dia está lindo e me sinto muito bem</td>\n",
              "      <td>[hoje, o, dia, está, lindo, e, me, sinto, muito, bem]</td>\n",
              "      <td>[hoje, dia, lindo, sinto, bem]</td>\n",
              "      <td>[hoj, dia, lind, sint, bem]</td>\n",
              "      <td>[hoje, dia, lir, sinto, bem]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Essa comida está horrível, não gostei.</td>\n",
              "      <td>essa comida está horrível não gostei</td>\n",
              "      <td>[essa, comida, está, horrível, não, gostei]</td>\n",
              "      <td>[comida, horrível, gostei]</td>\n",
              "      <td>[com, horr, gost]</td>\n",
              "      <td>[comida, horrível, gostar]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Estou muito feliz com o meu resultado!</td>\n",
              "      <td>estou muito feliz com o meu resultado</td>\n",
              "      <td>[estou, muito, feliz, com, o, meu, resultado]</td>\n",
              "      <td>[feliz, resultado]</td>\n",
              "      <td>[feliz, result]</td>\n",
              "      <td>[feliz, resultado]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Não suporto mais esse trânsit@o terrível.</td>\n",
              "      <td>não suporto mais esse trânsito terrível</td>\n",
              "      <td>[não, suporto, mais, esse, trânsito, terrível]</td>\n",
              "      <td>[suporto, trânsito, terrível]</td>\n",
              "      <td>[suport, trânsit, terr]</td>\n",
              "      <td>[suporto, trânsito, terrível]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Que filme% maravilhoso, adorei cada segundo.</td>\n",
              "      <td>que filme maravilhoso adorei cada segundo</td>\n",
              "      <td>[que, filme, maravilhoso, adorei, cada, segundo]</td>\n",
              "      <td>[filme, maravilhoso, adorei, cada, segundo]</td>\n",
              "      <td>[film, maravilh, ador, cad, segund]</td>\n",
              "      <td>[filme, maravilhoso, adorar, cada, segundo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Foi um desastre total, tudo deu errado.</td>\n",
              "      <td>foi um desastre total tudo deu errado</td>\n",
              "      <td>[foi, um, desastre, total, tudo, deu, errado]</td>\n",
              "      <td>[desastre, total, tudo, deu, errado]</td>\n",
              "      <td>[desastr, total, tud, deu, err]</td>\n",
              "      <td>[desastre, total, tudo, dar, errar]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Estou animado para o final# de semana!</td>\n",
              "      <td>estou animado para o final de semana</td>\n",
              "      <td>[estou, animado, para, o, final, de, semana]</td>\n",
              "      <td>[animado, final, semana]</td>\n",
              "      <td>[anim, final, seman]</td>\n",
              "      <td>[animar, final, semana]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>O atendimento foi péssimo, estou revoltado.</td>\n",
              "      <td>o atendimento foi péssimo estou revoltado</td>\n",
              "      <td>[o, atendimento, foi, péssimo, estou, revoltado]</td>\n",
              "      <td>[atendimento, péssimo, revoltado]</td>\n",
              "      <td>[atend, péss, revolt]</td>\n",
              "      <td>[atendimento, péssimo, revoltar]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ganhei um presente incr*ível hoje!</td>\n",
              "      <td>ganhei um presente incrível hoje</td>\n",
              "      <td>[ganhei, um, presente, incrível, hoje]</td>\n",
              "      <td>[ganhei, presente, incrível, hoje]</td>\n",
              "      <td>[ganh, pres, incr, hoj]</td>\n",
              "      <td>[ganhar, presente, incrível, hoje]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Me senti mal com aquele comentário.</td>\n",
              "      <td>me senti mal com aquele comentário</td>\n",
              "      <td>[me, senti, mal, com, aquele, comentário]</td>\n",
              "      <td>[senti, mal, comentário]</td>\n",
              "      <td>[sent, mal, coment]</td>\n",
              "      <td>[sentir, mal, comentário]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f023586-f677-4a27-9861-75f00f226c21')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f023586-f677-4a27-9861-75f00f226c21 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f023586-f677-4a27-9861-75f00f226c21');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-53f35c98-a32c-4081-bce0-4d77e1cf442c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53f35c98-a32c-4081-bce0-4d77e1cf442c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-53f35c98-a32c-4081-bce0-4d77e1cf442c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"'''\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Ganhei um presente incr*\\u00edvel hoje!\",\n          \"Essa comida est\\u00e1 horr\\u00edvel, n\\u00e3o gostei.\",\n          \"Foi um desastre total, tudo deu errado.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"texto_limpo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"ganhei um presente incr\\u00edvel hoje\",\n          \"essa comida est\\u00e1 horr\\u00edvel n\\u00e3o gostei\",\n          \"foi um desastre total tudo deu errado\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sem_stopwords\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemming\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatizacao\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnalisando os resultados, o stemming ajudou a deixar as palavras mais simples, mas às vezes cortou demais, como \"maravilh\", \"trânsit\" e \"coment\", que ficam difíceis de entender.\\nJá a lematização conseguiu deixar as palavras parecidas com o jeito correto de escrever, facilitando muito a leitura e o entendimento. \\nPor exemplo, \"ganh\" virou \"ganhar\" e \"coment\" virou \"comentário\", mantendo o sentido original.\\nPor isso, a lematização é melhor quando a gente precisa entender bem o texto, como em análise de sentimentos ou classificação. \\nO stemming pode ser útil em tarefas mais rápidas, tipo buscas ou agrupamentos, onde não precisa ser tão preciso.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisando os resultados, o stemming ajudou a deixar as palavras mais simples, mas às vezes cortou demais, como \"maravilh\", \"trânsit\" e \"coment\", que ficam difíceis de entender.\n",
        "Já a lematização conseguiu deixar as palavras parecidas com o jeito correto de escrever, facilitando muito a leitura e o entendimento.\n",
        "Por exemplo, \"ganh\" virou \"ganhar\" e \"coment\" virou \"comentário\", mantendo o sentido original.\n",
        "Por isso, a lematização é melhor quando a gente precisa entender bem o texto, como em análise de sentimentos ou classificação.\n",
        "O stemming pode ser útil em tarefas mais rápidas, tipo buscas ou agrupamentos, onde não precisa ser tão preciso."
      ],
      "metadata": {
        "id": "jzaHUV8For_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAREFAS:\n",
        "\n",
        "1. Pré-processamento básico de texto\n",
        "\n",
        "- Converter todo texto para letras minúsculas.\n",
        "\n",
        "- Remover pontuações, símbolos (ex.: vírgulas, pontos, exclamações).\n",
        "\n",
        "- Fazer tokenização simples dividindo o texto em palavras usando .split().\n",
        "\n",
        "2. Remover stopwords usando a biblioteca NLTK e a Spacy e comparar.\n",
        "\n",
        "3. Criar uma coluna nova com o texto pré-processado.\n",
        "\n",
        "4. Realizar a lemmatização e o Stemming e ver qual foi melhor, segundo o seu ponto de vista."
      ],
      "metadata": {
        "id": "wx0qUtRBeRsR"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "j4GyvwNwcGEk",
        "aDhjXxTlcVg6"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}